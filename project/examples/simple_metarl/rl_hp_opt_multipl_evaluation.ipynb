{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\")) #make the folder \"automl\" part of this\n",
    "\n",
    "RESULTS_PATH = 'results.csv'\n",
    "OPTUNA_DATABASE = 'study_results.db'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.loggers.result_logger import ResultLogger\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "from automl.utils.optuna_utils import load_study_from_database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = 'data\\\\experiments\\\\HyperparameterOptimizationPipeline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of HyperparameterOptimizationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_optimization_results : ResultLogger = ResultLogger(input={\n",
    "                                        \"logger_directory\" : experiment_path,\n",
    "                                        \"filename\" : RESULTS_PATH\n",
    "                                      })\n",
    "\n",
    "hyperparameter_optimization_results.proccess_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_study = load_study_from_database(database_path=hyperparameter_optimization_results.lg.logDir + '\\\\' + OPTUNA_DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_optimization_results.plot_bar_graph(x_axis='experiment', y_axis='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = vis.plot_param_importances(optuna_study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = vis.plot_parallel_coordinate(optuna_study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = vis.plot_intermediate_values(optuna_study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = vis.plot_optimization_history(optuna_study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_plot = [\"hidden_size\", \"hidden_layers\"]\n",
    "\n",
    "fig = vis.plot_contour(optuna_study, params=parameters_to_plot)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_plot = [\"epsilon_start\", \"epsilon_decay\", \"epsilon_end\"]\n",
    "\n",
    "fig = vis.plot_contour(optuna_study, params=parameters_to_plot)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global evaluation of configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_of_configurations : dict[str, ResultLogger] = {}\n",
    "\n",
    "for configuration_name in os.listdir(experiment_path):\n",
    "    configuration_path = os.path.join(experiment_path, configuration_name)\n",
    "    \n",
    "    if os.path.isdir(configuration_path):  # Ensure it's a file, not a subdirectory\n",
    "        \n",
    "        results_of_configurations[configuration_name] = ResultLogger(input={\n",
    "                                        \"logger_directory\" : configuration_path,\n",
    "                                        \"filename\" : RESULTS_PATH\n",
    "                                      })\n",
    "        results_of_configurations[configuration_name].proccess_input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Configurations:  {results_of_configurations.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global view of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for name, results_logger in results_of_configurations.items():\n",
    "\n",
    "    #results_logger.plot_graph(x_axis='episode', y_axis=[('total_reward', name)], to_show=False)\n",
    "    results_logger.plot_confidence_interval(x_axis='episode', y_column='total_reward', show_std=False, to_show=False, y_values_label=name, aggregate_number=2)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worst Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smaller study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations_to_study = [\"configuration_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for configuration_name in configurations_to_study:\n",
    "    \n",
    "    results_logger = results_of_configurations[configuration_name]\n",
    "\n",
    "    #results_logger.plot_graph(x_axis='episode', y_axis=[('total_reward', name)], to_show=False)\n",
    "    results_logger.plot_confidence_interval(x_axis='episode', y_column='total_reward',show_std=False, to_show=False, y_values_label=configuration_name, aggregate_number=2)\n",
    "    results_logger.plot_linear_regression(x_axis='episode', y_axis='total_reward', to_show=False, y_label=configuration_name + '_linear')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_to_study : dict[str, ResultLogger]= {}\n",
    "\n",
    "for configuration_name in configurations_to_study:\n",
    "    \n",
    "    results_logger = results_of_configurations[configuration_name]\n",
    "    \n",
    "    for agent_name in [\"agent_1\", \"agent_2\"]:\n",
    "      \n",
    "        agent_results_logger = ResultLogger(input={\n",
    "                                            \"logger_directory\" : f\"{results_logger.lg.logDir}\\\\{agent_name}\",\n",
    "                                            \"filename\" : RESULTS_PATH\n",
    "                                          })\n",
    "\n",
    "        agents_to_study[f\"{configuration_name}_{agent_name}\"] = agent_results_logger\n",
    "        \n",
    "        agent_results_logger.proccess_input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent_name, agent_results_logger in agents_to_study.items():\n",
    "    \n",
    "    #results_logger.plot_graph(x_axis='episode', y_axis=[('total_reward', name)], to_show=False)\n",
    "    agent_results_logger.plot_confidence_interval(x_axis='episode', y_column='total_reward',show_std=False, to_show=False, y_values_label=agent_name, aggregate_number=2)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
