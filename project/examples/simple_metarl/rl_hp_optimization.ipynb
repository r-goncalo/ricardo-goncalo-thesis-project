{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\")) #make the folder \"automl\" part of this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization Experiment Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOCKUP = False #if to use mockup components in experiment (for testing general logic without having to do a lot of computations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_experiment_path = \"data\\\\experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.rl.environment.gymnasium_env import GymnasiumEnvironmentWrapper\n",
    "\n",
    "# Choose environment to test\n",
    "\n",
    "environment_to_test = (GymnasiumEnvironmentWrapper, {})\n",
    "#environment_to_test = None # this would mean to use the default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To help distinguish experiments using the environment\n",
    "\n",
    "#base_experiment_path = os.path.join(base_experiment_path, \"CartPole\")\n",
    "base_experiment_path = os.path.join(base_experiment_path, \"MountainCar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rgoncalo\\anaconda3\\envs\\AIPython\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Which base experiment to follow\n",
    "\n",
    "import scripts.basic_dqn_hp_experiment as experiment\n",
    "#import scripts.basic_ppo_hp_experiment as experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to help distinguish experiments using specifications of algorithms\n",
    "#base_experiment_path = os.path.join(base_experiment_path, \"DQN\")\n",
    "#base_experiment_path = os.path.join(base_experiment_path, \"DQN_SB3_TRAINED\")\n",
    "base_experiment_path = os.path.join(base_experiment_path, \"DQN_SB3_SEMI_TRAINED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_optimization_input = {\n",
    "    \"n_trials\" : 5,\n",
    "    \"steps\" : 2,\n",
    "    \"base_directory\" :  base_experiment_path,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to generate the hyperparameters to change\n",
    "\n",
    "\n",
    "hyperparameters_to_change = None\n",
    "\n",
    "#hyperparameters_to_change : list = experiment.get_hyperparameters_to_change()\n",
    "\n",
    "if hyperparameters_to_change != None:\n",
    "    hp_optimization_input[\"hyperparameters_to_change\"] = hyperparameters_to_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to pass the component to optimize by giving directly its configuration dict\n",
    "\n",
    "\n",
    "configuration_dict = None\n",
    "\n",
    "#configuration_dict = experiment.get_configuration_dict(num_episodes=500, env=environment_to_test, mockup=MOCKUP)\n",
    "\n",
    "\n",
    "# from automl.base_configurations.environment.montain_car.dqn_sb3 import config_dict as dqn_sb3_config_dict\n",
    "#configuration_dict = dqn_sb3_config_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to pass the component to optimize by giving directly its path\n",
    "\n",
    "base_component_configuration_path = None\n",
    "\n",
    "#base_component_configuration_path = \"data\\\\experiments\\\\MountainCar\\\\DQN\\\\to_optimize_configuration.json\"\n",
    "base_component_configuration_path = os.path.join(base_experiment_path, \"to_optimize_configuration.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.rl.evaluators.rl_std_avg_evaluator import LastValuesAvgStdEvaluator\n",
    "from automl.rl.evaluators.rl_evaluator_player import EvaluatorWithPlayer\n",
    "\n",
    "\n",
    "#evaluator = None\n",
    "#evaluator = (LastValuesAvgStdEvaluator, {\"value_to_use\" : \"episode_steps\"})\n",
    "evaluator = (EvaluatorWithPlayer, {\"base_evaluator\" : (LastValuesAvgStdEvaluator, {\"value_to_use\" : \"episode_steps\"})})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Pruner\n",
    "\n",
    "import optuna\n",
    "\n",
    "\n",
    "pruner = None\n",
    "#pruner = optuna.pruners.PercentilePruner(percentile=25.0)\n",
    "\n",
    "if pruner != None:\n",
    "    hp_optimization_input[\"pruner\"] = pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if configuration_dict != None:\n",
    "    hp_optimization_input[\"configuration_dict\"] = configuration_dict\n",
    "    \n",
    "    \n",
    "if base_component_configuration_path != None: \n",
    "    hp_optimization_input[\"base_component_configuration_path\"] = base_component_configuration_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to load the basic configuration of the hyperparameter optimization pipeline\n",
    "\n",
    "hp_optimization_pipeline_path = None\n",
    "\n",
    "hp_optimization_pipeline_path = os.path.join(base_experiment_path, \"configuration.json\")\n",
    "#hp_optimization_pipeline_path = \"data\\\\experiments\\\\MountainCar\\\\DQN\\\\configuration.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Path does not exist: data\\experiments\\MountainCar\\DQN_SB3_SEMI_TRAINED\\configuration.json",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hp_optimization_pipeline_path != \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;66;03m# load the configuration in the path\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautoml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjson_component_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_component_from_path\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     hp_optimization_pipeline = \u001b[43mgen_component_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp_optimization_pipeline_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# if not, generate empty\u001b[39;00m\n\u001b[32m      9\u001b[39m     hp_optimization_pipeline = HyperparameterOptimizationPipeline()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rgoncalo\\Universidade\\ricardo-goncalo-thesis-project\\project\\automl\\utils\\json_component_utils.py:496\u001b[39m, in \u001b[36mgen_component_from_path\u001b[39m\u001b[34m(path, parent_component_for_generated)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautoml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile_component_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_component_in_directory, gen_component_in_file_path\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(path):\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPath does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m os.path.isdir(path):\n\u001b[32m    499\u001b[39m     generated_component =  gen_component_in_directory(path, parent_component_for_generated)\n",
      "\u001b[31mException\u001b[39m: Path does not exist: data\\experiments\\MountainCar\\DQN_SB3_SEMI_TRAINED\\configuration.json"
     ]
    }
   ],
   "source": [
    "from automl.meta_rl.hp_optimization_pipeline import HyperparameterOptimizationPipeline\n",
    "\n",
    "if hp_optimization_pipeline_path != None: # load the configuration in the path\n",
    "    \n",
    "    from automl.utils.json_component_utils import gen_component_from_path\n",
    "    hp_optimization_pipeline = gen_component_from_path(hp_optimization_pipeline_path)\n",
    "\n",
    "else: # if not, generate empty\n",
    "    hp_optimization_pipeline = HyperparameterOptimizationPipeline()\n",
    "    \n",
    "    \n",
    "hp_optimization_pipeline.pass_input(hp_optimization_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_optimization_pipeline.setup_files() # partially initialize the hp optimization pipeline with the current input, it can be manually changed before it is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_directory = hp_optimization_pipeline.get_artifact_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we can make manual changes to the generated json files:\n",
    "\n",
    " - to_optimize_configuration.json, which is the base in which we want to optimize the hyperparameters of\n",
    " - configuration.json, the definition of the actual hyperparameter optimization experiment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_optimization_pipeline.save_configuration() # save the configuration as is to, even if the process is interrupted, we can see the added values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Hyperparameter Configuration Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.basic_components.state_management import load_component_from_folder\n",
    "\n",
    "# load the defined experiment with its changes\n",
    "hp_optimization_pipeline : HyperparameterOptimizationPipeline = load_component_from_folder(experiment_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#torch.autograd.set_detect_anomaly(True) # use this in case of certain types of errors\n",
    "hp_optimization_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.basic_components.state_management import save_state\n",
    "\n",
    "save_state(hp_optimization_pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIPython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
