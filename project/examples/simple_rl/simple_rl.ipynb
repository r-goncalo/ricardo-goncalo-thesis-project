{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_STORE_EXPERIMENTS = \"data\\\\rl_training\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RL Pipeline structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from automl.base_configurations.environment.cart_pole import dqn_sb3 as base_rl_configuration\n",
    "from automl.base_configurations.environment.cart_pole import ppo_sb3 as base_rl_configuration\n",
    "\n",
    "\n",
    "rl_pipeline_config = base_rl_configuration.config_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rl_pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment_name = \"dqn_sb3_cartpole\"\n",
    "#experiment_name = \"dqn_sb3_cartpole_ppo\"\n",
    "\n",
    "experiment_name = \"ppo_cartpole\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = rl_pipeline_config[\"input\"][\"environment\"]\n",
    "environment_input = environment[1]\n",
    "\n",
    "#environment_input[\"render_mode\"] = \"human\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_pipeline_input = rl_pipeline_config[\"input\"]\n",
    "\n",
    "rl_trainer_tuple = rl_pipeline_input[\"rl_trainer\"]\n",
    "rl_trainer_input = rl_trainer_tuple[1]\n",
    "\n",
    "agents_input = rl_pipeline_input[\"agents_input\"]\n",
    "\n",
    "policy_tuple = agents_input[\"policy\"]\n",
    "policy_input = policy_tuple[1]\n",
    "\n",
    "agents_trainers_input = rl_trainer_input[\"agents_trainers_input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_tuple = agents_trainers_input[\"learner\"]\n",
    "learner_input = learner_tuple[1]\n",
    "\n",
    "optimizer_tuple = learner_input[\"optimizer\"]\n",
    "optimizer_input = optimizer_tuple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if LOAD_MODEL:\n",
    "\n",
    "    #base_model_path = 'data\\\\models\\\\sb3_CartPole_dqn\\\\sb3_CartPole_dqn_perturbed_0_10'\n",
    "    #base_model_path = 'data\\\\models\\\\sb3_CartPole_dqn\\\\sb3_CartPole_dqn_perturbed_5_50'\n",
    "    base_model_path = 'data\\\\models\\\\sb3_CartPole_ppo\\\\sb3_CartPole_ppo_gaussian_0_0.8_0.9'\n",
    "\n",
    "    #base_model_path = 'data\\\\models\\\\FC_CartPole_ppo\\\\FC_CartPole_ppo'\n",
    "    \n",
    "    from automl.utils.json_utils.shape_json_utils import CustomSpaceJsonEncoderDecoder\n",
    "    \n",
    "    model_name = os.path.basename(base_model_path)\n",
    "    \n",
    "    experiment_name = f\"{experiment_name}\\\\{model_name}\"\n",
    "    \n",
    "    rl_pipeline_input = rl_pipeline_config[\"input\"]\n",
    "    \n",
    "    policy_input[\"model\"] = base_model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_input[\"critic_model\"] = 'data\\\\models\\\\sb3_CartPole_ppo_critic\\\\sb3_CartPole_ppo_critic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rl_trainer_input[\"limit_total_steps\"] = 90000\n",
    "\n",
    "#rl_trainer_input.pop(\"limit_total_steps\", None)\n",
    "\n",
    "#rl_trainer_input[\"num_episodes\"] = 4000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agents_trainers_input[\"learning_start_step_delay\"] = 5000\n",
    "#agents_trainers_input[\"learning_start_ep_delay\"] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agents_trainers_input[\"optimization_interval\"] = 2048\n",
    "#agents_trainers_input[\"times_to_learn\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#optimizer_input[\"clip_grad_norm\"] = 0.1\n",
    "#optimizer_input[\"clip_grad_value\"] = 0.1\n",
    "#optimizer_tuple = learner_input[\"learning_rate\"] = 0.0012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gen RL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from automl.rl.rl_pipeline import RLPipelineComponent\n",
    "from automl.utils.json_utils.json_component_utils import gen_component_from\n",
    "\n",
    "rl_pipeline : RLPipelineComponent = gen_component_from(rl_pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_pipeline.pass_input({\"base_directory\" : PATH_TO_STORE_EXPERIMENTS,\n",
    "                        \"artifact_relative_directory\" : experiment_name,\n",
    "                        \"create_new_directory\" : True})\n",
    "\n",
    "experiment_path = rl_pipeline.get_artifact_directory()\n",
    "\n",
    "print(f\"Experiment path: {experiment_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.loggers.global_logger import activate_global_logger\n",
    "\n",
    "activate_global_logger(rl_pipeline.get_artifact_directory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rl_pipeline.save_configuration(save_exposed_values=True)\n",
    "from automl.basic_components.state_management import save_state\n",
    "\n",
    "\n",
    "save_state(rl_pipeline, save_definition=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGGREGATE_NUMBER = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from automl.loggers.result_logger import RESULTS_FILENAME, ResultLogger\n",
    "\n",
    "results_directory = f\"{experiment_path}\\\\RLTrainerComponent\"\n",
    "    \n",
    "results_logger = ResultLogger(input={\n",
    "                                        \"results_filename\" : RESULTS_FILENAME,\n",
    "                                        \"base_directory\" : results_directory,\n",
    "                                        \"artifact_relative_directory\" : '',\n",
    "                                        \"create_new_directory\" : False\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_logger.plot_graph(x_axis='episode', y_axis=[('total_reward', name)], to_show=False)\n",
    "results_logger.plot_confidence_interval(x_axis='episode', y_column='episode_reward',show_std=False, to_show=False, y_values_label=experiment_name, aggregate_number=AGGREGATE_NUMBER)\n",
    "results_logger.plot_linear_regression(x_axis='episode', y_axis='episode_reward', to_show=False, y_label=experiment_name + '_linear')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIPython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
