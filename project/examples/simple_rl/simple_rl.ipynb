{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\")) #make the folder \"automl\" part of this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from automl.rl_components.rl_trainer_component import RLTrainerComponent\n",
    "from automl.rl_components.agent_components import AgentComponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Opening a log... Log Dir: data\\logs Log Name:\n",
      "Log directory did not exist, creating it at: data\\logs\\log_20\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../..\")) #make the folder \"project\" part of this\n",
    "\n",
    "from project.logger import Log\n",
    "\n",
    "lg = Log.openLog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pettingzoo.butterfly import cooperative_pong_v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_translator(state, device):\n",
    "    return torch.from_numpy(state).to(torch.float32).to(device)\n",
    "\n",
    "class Env(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.env = cooperative_pong_v5.env(render_mode=\"none\")\n",
    "        self.env.reset()\n",
    "        \n",
    "    def set_device(self, device):\n",
    "        self.device = device\n",
    "        \n",
    "    def __str__(self):\n",
    "        \n",
    "        return \"Petting zoo cooperative pong v5\"\n",
    "        \n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "        \n",
    "    def observe(self, *args):\n",
    "        return state_translator(self.env.observe(*args), self.device)\n",
    "        \n",
    "    def agents(self):\n",
    "        return self.env.agents\n",
    "    \n",
    "    def action_space(self, *args):\n",
    "        return self.env.action_space(*args)\n",
    "    \n",
    "    def last(self):\n",
    "        \n",
    "        observation, reward, termination, truncation, info = self.env.last()\n",
    "        \n",
    "        #returns state, reward, done, info\n",
    "        return state_translator(observation, self.device), reward, termination, info\n",
    "    \n",
    "    def agent_iter(self):\n",
    "        \n",
    "        return self.env.agent_iter()\n",
    "    \n",
    "    def step(self, *args):\n",
    "        \n",
    "        return self.env.step(*args)\n",
    "    \n",
    "    def rewards(self):\n",
    "        return self.env.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 2\n",
    "state_memory_size = 1\n",
    "limit_steps = 60\n",
    "optimization_interval = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL Trainer Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from automl.rl_components.rl_pipeline import RLPipelineComponent\n",
    "\n",
    "env = Env()\n",
    "\n",
    "rl_pipeline_input = {\n",
    "    \"device\" : \"gpu\",\n",
    "    \"logger\" : lg,\n",
    "    \"num_episodes\" : num_episodes,\n",
    "    \"state_memory_size\" : state_memory_size,\n",
    "    \"environment\" : env,\n",
    "    \"limit_steps\" : limit_steps ,\n",
    "    \"optimization_interval\" : optimization_interval\n",
    "}\n",
    "\n",
    "\n",
    "rl_pipeline = RLPipelineComponent(input=rl_pipeline_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RLPipelineComponent: Trying to use cuda...\n",
      "RLPipelineComponent: There was an error trying to setup the device in 'gpu': Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu\n",
      "RLPipelineComponent: The model will trained and evaluated on: cpu\n",
      "RLPipelineComponent: Creating agents\n",
      "Opening a log... Log Dir: data\\logs\\log_20 Log Name:agent_1\n",
      "Log directory did not exist, creating it at: data\\logs\\log_20\\agent_1\n",
      "RLPipelineComponent: State for agent agent_1 has shape: Z: 280 Y: 480 X: 3\n",
      "Action space of agent paddle_0: Discrete(3)\n",
      "RLPipelineComponent: Created agent in training agent_1\n",
      "Opening a log... Log Dir: data\\logs\\log_20 Log Name:agent_2\n",
      "Log directory did not exist, creating it at: data\\logs\\log_20\\agent_2\n",
      "RLPipelineComponent: State for agent agent_2 has shape: Z: 280 Y: 480 X: 3\n",
      "Action space of agent paddle_1: Discrete(3)\n",
      "RLPipelineComponent: Created agent in training agent_2\n",
      "RLPipelineComponent: Initialized {'paddle_0': <automl.rl_components.agent_components.AgentComponent object at 0x000001C9B049AA30>, 'paddle_1': <automl.rl_components.agent_components.AgentComponent object at 0x000001C9B049A700>} agents\n",
      "RLPipelineComponent: Initializing trainer\n",
      "RLTrainerComponent: Starting to run episodes of training\n",
      "RLTrainerComponent: Starting to run episode 0\n",
      "agent_1: Batch size: 64 Gamma: 0.95\n",
      "agent_1: Initializing policy model...\n",
      "agent_1: Creating policy model using default values and passed shape...\n",
      "agent_1: Initializing target model...\n",
      "Initializing model with input{'board_x': 3, 'board_y': 480, 'board_z': 280, 'output_size': 3, 'device': device(type='cpu')}\n",
      "Cloning model\n",
      "Initializing model with input{'board_x': 3, 'board_y': 480, 'board_z': 280, 'output_size': 3, 'device': device(type='cpu')}\n",
      "RLTrainerComponent: In episode 0, optimizing at step 0 that is the total step 0\n",
      "RLTrainerComponent: Optimizing agent agent_1\n",
      "RLTrainerComponent: Optimization took 0.0 seconds\n",
      "RLTrainerComponent: Optimizing agent AgentComponent\n",
      "agent_2: Batch size: 64 Gamma: 0.95\n",
      "agent_2: Initializing policy model...\n",
      "agent_2: Creating policy model using default values and passed shape...\n",
      "agent_2: Initializing target model...\n",
      "Initializing model with input{'board_x': 3, 'board_y': 480, 'board_z': 280, 'output_size': 3, 'device': device(type='cpu')}\n",
      "Cloning model\n",
      "Initializing model with input{'board_x': 3, 'board_y': 480, 'board_z': 280, 'output_size': 3, 'device': device(type='cpu')}\n",
      "RLTrainerComponent: Optimization took 0.8030407428741455 seconds\n",
      "RLTrainerComponent: In episode 0, optimizing at step 50 that is the total step 50\n",
      "RLTrainerComponent: Optimizing agent agent_1\n",
      "RLTrainerComponent: Optimization took 0.0 seconds\n",
      "RLTrainerComponent: Optimizing agent agent_2\n",
      "RLTrainerComponent: Optimization took 0.0 seconds\n",
      "RLTrainerComponent: In episode 0, reached step 60 that is beyond the current limit, 60\n",
      "RLTrainerComponent: Ended episode: 0 with duration: 60, total reward: 0 and real time duration of 2.0519368648529053 seconds\n",
      "RLTrainerComponent: Starting to run episode 1\n",
      "RLTrainerComponent: In episode 1, optimizing at step 40 that is the total step 100\n",
      "RLTrainerComponent: Optimizing agent agent_1\n",
      "RLTrainerComponent: Optimization took 0.0 seconds\n",
      "RLTrainerComponent: Optimizing agent agent_2\n",
      "RLTrainerComponent: Optimization took 0.0 seconds\n",
      "RLTrainerComponent: Ended episode: 1 with duration: 60, total reward: 0 and real time duration of 0.8219797611236572 seconds\n",
      "RLTrainerComponent: \n",
      "Training took 2.87492299079895 seconds, 0.02395769158999125 per step (120)\n"
     ]
    }
   ],
   "source": [
    "rl_pipeline.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making design for RLPipelineComponent\n",
      "Looking at input with key device and type <class 'str'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key logger and type <class 'project.logger.Log.LogClass'>\n",
      "not component nor connector\n",
      "Looking at input with key num_episodes and type <class 'int'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key state_memory_size and type <class 'int'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key environment and type <class '__main__.Env'>\n",
      "not component nor connector\n",
      "Looking at input with key limit_steps and type <class 'int'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key optimization_interval and type <class 'int'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key agents and type <class 'dict'>\n",
      "not component nor connector\n",
      "Looking at input with key save_interval and type <class 'int'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key rl_trainer and type <class 'str'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key created_agents_input and type <class 'dict'>\n",
      "not component nor connector\n"
     ]
    }
   ],
   "source": [
    "system_design = rl_pipeline.get_design()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"RLPipelineComponent\",\n",
      "{\n",
      "  \"device\" : gpu\n",
      "  \"num_episodes\" : 2\n",
      "  \"state_memory_size\" : 1\n",
      "  \"limit_steps\" : 60\n",
      "  \"optimization_interval\" : 50\n",
      "  \"save_interval\" : 100\n",
      "  \"rl_trainer\" : \n",
      "},\n",
      "{\n",
      "},\n",
      "{\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from automl.component_designer import print_design\n",
    "\n",
    "print_design(system_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.component_designer import design\n",
    "\n",
    "reconstructued_component = design(system_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making design for RLPipelineComponent\n",
      "Looking at input with key device and type <class 'str'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key num_episodes and type <class 'int'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key state_memory_size and type <class 'int'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key limit_steps and type <class 'int'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key optimization_interval and type <class 'int'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key save_interval and type <class 'int'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "Looking at input with key rl_trainer and type <class 'str'>\n",
      "not component nor connector\n",
      "is int, float or str\n",
      "(\"RLPipelineComponent\",\n",
      "{\n",
      "  \"device\" : gpu\n",
      "  \"num_episodes\" : 2\n",
      "  \"state_memory_size\" : 1\n",
      "  \"limit_steps\" : 60\n",
      "  \"optimization_interval\" : 50\n",
      "  \"save_interval\" : 100\n",
      "  \"rl_trainer\" : \n",
      "},\n",
      "{\n",
      "},\n",
      "{\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reconstructued_design = reconstructued_component.get_design()\n",
    "\n",
    "\n",
    "print_design(reconstructued_design)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
