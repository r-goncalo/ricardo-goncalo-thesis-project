{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.ml.models.torch_model_components import TorchModelComponent\n",
    "from automl.utils.file_component_utils import gen_component_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model from complex configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if True:\n",
    "\n",
    "    from automl.core.localizations import get_component_by_localization\n",
    "    from automl.external_support.sb3.sb3_model_wrapper import SB3WrapperTorch\n",
    "    from automl.loggers.component_with_results import Component\n",
    "    \n",
    "    \n",
    "\n",
    "    component_with_model_path = \"C:\\\\Experiments\\\\rl-zoo-CartPole-dqn-2\\\\HPOptimizationExperiments\\\\2\\\\experiments\\\\original\\\\configuration_57\"\n",
    "    component_with_model : Component = gen_component_from_path(component_with_model_path)\n",
    "\n",
    "    model_name = \"FullyConnectedModelSchema\"\n",
    "\n",
    "    model : TorchModelComponent = get_component_by_localization(component_with_model, [( \"__get_by_name__\", {\"name_of_component\" : model_name})])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model from direct configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "\n",
    "    model_path = \"C:\\\\Experiments\\\\rl-zoo-CartPole-dqn-2\\\\models\\\\sb3_CartPole_dqn\"\n",
    "    model : TorchModelComponent = gen_component_from_path(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize loaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute input and output shape from Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.rl.environment.gymnasium_env import GymnasiumEnvironmentWrapperSampler as env_class\n",
    "\n",
    "env = (env_class, {\"environment\" : cart})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "<class 'automl.ml.models.neural_model.FullyConnectedModelSchema'> needs input shape to be passed to setup its values, input: {'base_directory': <automl.rl.policy.qpolicy.QPolicy object at 0x000002A501376AD0>, 'hidden_layers': 2, 'hidden_size': 256, 'artifact_relative_directory': 'FullyConnectedModelSchema', 'create_new_directory': False, 'device': 'cpu', 'logger_object': <automl.loggers.logger_component.LoggerSchema object at 0x000002A5013D8D10>, 'logger_input': {}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model.pass_input({\u001b[33m\"\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m\"\u001b[39m : \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproccess_input_if_not_proccesd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ricardo-goncalo-thesis-project\\project\\automl\\component.py:326\u001b[39m, in \u001b[36mComponent.proccess_input_if_not_proccesd\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__input_is_being_processed:\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIn component of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, when cheking for the inputs: Input is already being processed, there is probably a recursive call to proccess_input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproccess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ricardo-goncalo-thesis-project\\project\\automl\\component.py:303\u001b[39m, in \u001b[36mComponent.proccess_input\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mproccess_input\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    299\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    300\u001b[39m \u001b[33;03m    This method is called by external parties\u001b[39;00m\n\u001b[32m    301\u001b[39m \u001b[33;03m    Instead of extending it, extend proccess_input_internal\u001b[39;00m\n\u001b[32m    302\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_proccess_input_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m     \u001b[38;5;28mself\u001b[39m.__input_was_proccessed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m.__input_is_being_processed = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ricardo-goncalo-thesis-project\\project\\automl\\ml\\models\\neural_model.py:59\u001b[39m, in \u001b[36mFullyConnectedModelSchema._proccess_input_internal\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_proccess_input_internal\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_proccess_input_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ricardo-goncalo-thesis-project\\project\\automl\\ml\\models\\torch_model_components.py:28\u001b[39m, in \u001b[36mTorchModelComponent._proccess_input_internal\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_proccess_input_internal\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_proccess_input_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mself\u001b[39m.__synchro_model_value_attr()\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mself\u001b[39m._setup_model()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ricardo-goncalo-thesis-project\\project\\automl\\ml\\models\\model_components.py:18\u001b[39m, in \u001b[36mModelComponent._proccess_input_internal\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_proccess_input_internal\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     16\u001b[39m     \u001b[38;5;28msuper\u001b[39m()._proccess_input_internal()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ricardo-goncalo-thesis-project\\project\\automl\\ml\\models\\neural_model.py:66\u001b[39m, in \u001b[36mFullyConnectedModelSchema._setup_values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28msuper\u001b[39m()._setup_values()    \n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_shape == \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m needs input shape to be passed to setup its values, input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.input\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_shape == \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m needs output shape to be passed to setup its values, input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.input\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mException\u001b[39m: <class 'automl.ml.models.neural_model.FullyConnectedModelSchema'> needs input shape to be passed to setup its values, input: {'base_directory': <automl.rl.policy.qpolicy.QPolicy object at 0x000002A501376AD0>, 'hidden_layers': 2, 'hidden_size': 256, 'artifact_relative_directory': 'FullyConnectedModelSchema', 'create_new_directory': False, 'device': 'cpu', 'logger_object': <automl.loggers.logger_component.LoggerSchema object at 0x000002A5013D8D10>, 'logger_input': {}}"
     ]
    }
   ],
   "source": [
    "model.pass_input({\"device\" : \"cpu\"})\n",
    "model.proccess_input_if_not_proccesd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vizualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.ml.models.torch_model_utils import plot_weight_hist, plot_fc_weights, print_weight_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weight_hist(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fc_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_weight_norms(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"data\\\\models\"\n",
    "models_path = f\"{models_path}\\\\{model.name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_model = model.clone(\n",
    "    input_for_clone={\n",
    "        \"base_directory\" : models_path,\n",
    "        \"create_new_directory\": True,\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloned_model.save_state(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIPython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
