{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook substitutes some classes in an experience by \"debug\" versions of them, which write to file almost every intermidiate step, as to help detect any incoherence in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_STORE_EXPERIMENTS = \"data\\\\rl_training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment_name = \"dqn_sb3_cartpole\"\n",
    "#experiment_name = \"dqn_sb3_cartpole_ppo\"\n",
    "\n",
    "experiment_name = \"dqn_cartpole\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation before loading experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change logging system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.loggers.logger_component import LoggerSchema \n",
    "\n",
    "\n",
    "LoggerSchema.get_schema_parameter_signature(\"write_to_file_when_text_lines_over\").change_default_value(-1)\n",
    "LoggerSchema.get_schema_parameter_signature(\"necessary_logger_level\").change_default_value(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.loggers.component_with_results import ResultLogger\n",
    "\n",
    "\n",
    "ResultLogger.get_schema_parameter_signature(\"save_results_on_log\").change_default_value(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The base Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.base_configurations.environment.cart_pole import dqn_sb3 as base_rl_configuration\n",
    "#from automl.base_configurations.environment.cart_pole import ppo_sb3 as base_rl_configuration\n",
    "\n",
    "\n",
    "rl_pipeline_config = base_rl_configuration.config_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Configuration Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_pipeline_input = rl_pipeline_config[\"input\"]\n",
    "\n",
    "rl_trainer_tuple = rl_pipeline_input[\"rl_trainer\"]\n",
    "rl_trainer_input = rl_trainer_tuple[1]\n",
    "\n",
    "agents_input = rl_pipeline_input[\"agents_input\"]\n",
    "\n",
    "policy_tuple = agents_input[\"policy\"]\n",
    "policy_input = policy_tuple[1]\n",
    "\n",
    "agents_trainers_input = rl_trainer_input[\"agents_trainers_input\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_tuple = agents_trainers_input[\"learner\"]\n",
    "learner_input = learner_tuple[1]\n",
    "\n",
    "optimizer_tuple = learner_input[\"optimizer\"]\n",
    "optimizer_input = optimizer_tuple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_tuple = agents_trainers_input[\"memory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = rl_pipeline_config[\"input\"][\"environment\"]\n",
    "environment_input = environment[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes to the base configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to help alter experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_value_in_dict(dict_with_value : dict, key, new_value):\n",
    "    print(f\"Old value for key '{key}': {dict_with_value.get(key, None)}, new value: {new_value}\")\n",
    "    dict_with_value[key] = new_value\n",
    "\n",
    "def remove_value_in_dict(dict_with_value : dict, key, new_value):\n",
    "    print(f\"Old value for key '{key}': {dict_with_value.get(key, None)}, to be removed...\")\n",
    "    dict_with_value.pop(key, None)\n",
    "\n",
    "\n",
    "\n",
    "def substitute_tuple_value_in_dict(dict_with_tuple : dict, key, tuple_index, new_value):\n",
    "\n",
    "    tuple_value : tuple = dict_with_tuple[key]\n",
    "\n",
    "    print(f\"Old value for tuple pos {tuple_index}: {tuple_value[tuple_index]}, new value: {new_value}\")\n",
    "    new_tuple_value = tuple( new_value if tuple_index == i else tuple_value[i] for i in range(len(tuple_value)) )\n",
    "\n",
    "    dict_with_tuple[key] = new_tuple_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if LOAD_MODEL:\n",
    "\n",
    "    base_model_path = 'data\\\\models\\\\sb3_CartPole_dqn\\\\sb3_CartPole_dqn_perturbed_0_10'\n",
    "    #base_model_path = 'data\\\\models\\\\sb3_CartPole_dqn\\\\sb3_CartPole_dqn_perturbed_5_50'\n",
    "    #base_model_path = 'data\\\\models\\\\sb3_CartPole_ppo\\\\sb3_CartPole_ppo_gaussian_0_0.8_0.9'\n",
    "\n",
    "    #base_model_path = 'data\\\\models\\\\FC_CartPole_ppo\\\\FC_CartPole_ppo'\n",
    "        \n",
    "    model_name = os.path.basename(base_model_path)\n",
    "    \n",
    "    experiment_name = f\"{experiment_name}\\\\{model_name}\"\n",
    "        \n",
    "    policy_input[\"model\"] = base_model_path\n",
    "\n",
    "    #learner_input[\"critic_model\"] = 'data\\\\models\\\\sb3_CartPole_ppo_critic\\\\sb3_CartPole_ppo_critic'\n",
    "\n",
    "else:\n",
    "    experiment_name = f\"{experiment_name}\\\\original\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other value changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rl_trainer_input[\"limit_total_steps\"] = 1000\n",
    "\n",
    "#rl_trainer_input.pop(\"limit_total_steps\", None)\n",
    "\n",
    "#rl_trainer_input[\"num_episodes\"] = 4000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agents_trainers_input[\"learning_start_step_delay\"] = 5000\n",
    "#agents_trainers_input[\"learning_start_ep_delay\"] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agents_trainers_input[\"optimization_interval\"] = 2048\n",
    "\n",
    "#substitute_value_in_dict(agents_trainers_input, \"times_to_learn\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer_input[\"clip_grad_norm\"] = 0.1\n",
    "#substitute_value_in_dict(optimizer_input, \"clip_grad_value\", 0.1)\n",
    "\n",
    "#substitute_value_in_dict(optimizer_input, \"learning_rate\", 0.0012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen RL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from automl.rl.rl_pipeline import RLPipelineComponent\n",
    "from automl.utils.json_utils.json_component_utils import gen_component_from\n",
    "\n",
    "rl_pipeline : RLPipelineComponent = gen_component_from(rl_pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_pipeline.pass_input({\"base_directory\" : PATH_TO_STORE_EXPERIMENTS,\n",
    "                        \"artifact_relative_directory\" : experiment_name,\n",
    "                        \"create_new_directory\" : True})\n",
    "\n",
    "experiment_path = rl_pipeline.get_artifact_directory()\n",
    "\n",
    "print(f\"Experiment path: {experiment_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.loggers.global_logger import activate_global_logger\n",
    "\n",
    "activate_global_logger(rl_pipeline.get_artifact_directory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_pipeline.proccess_input_if_not_proccesd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rl_pipeline.save_configuration(save_exposed_values=True)\n",
    "from automl.basic_components.state_management import save_state\n",
    "\n",
    "\n",
    "save_state(rl_pipeline, save_definition=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGGREGATE_NUMBER = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from automl.loggers.result_logger import RESULTS_FILENAME, ResultLogger\n",
    "\n",
    "results_directory = f\"{experiment_path}\\\\RLTrainerComponent\"\n",
    "    \n",
    "results_logger = ResultLogger(input={\n",
    "                                        \"results_filename\" : RESULTS_FILENAME,\n",
    "                                        \"base_directory\" : results_directory,\n",
    "                                        \"artifact_relative_directory\" : '',\n",
    "                                        \"create_new_directory\" : False\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_logger.plot_graph(x_axis='episode', y_axis=[('total_reward', name)], to_show=False)\n",
    "results_logger.plot_confidence_interval(x_axis='episode', y_column='episode_reward',show_std=True, to_show=False, y_values_label=experiment_name, aggregate_number=AGGREGATE_NUMBER)\n",
    "results_logger.plot_linear_regression(x_axis='episode', y_axis='episode_reward', to_show=False, y_label=experiment_name + '_linear')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIPython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
