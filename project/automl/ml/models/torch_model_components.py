import os
from automl.basic_components.state_management import StatefulComponent
from automl.loggers.global_logger import globalWriteLine
from project.automl.loggers.logger_component import ComponentWithLogging
import torch
import torch.nn as nn

from automl.component import InputSignature, requires_input_proccess
from automl.ml.models.model_components import ModelComponent

class TorchModelComponent(ModelComponent, StatefulComponent, ComponentWithLogging):
    
    
    # INITIALIZATION --------------------------------------------------------------------------

    parameters_signature = {
        "device": InputSignature(get_from_parent=True, ignore_at_serialization=True),
        "model" : InputSignature(mandatory=False, possible_types=[nn.Module])
    }    

    exposed_values = {
        "model" : None
    }
    
    def _proccess_input_internal(self):
        
        super()._proccess_input_internal()

        self.__synchro_model_value_attr()
                        
        self._setup_model()

        self.device = self.get_input_value("device")
        
        if self.device != None:
            self.model.to(self.device)


    def __synchro_model_value_attr(self):

        '''To call mainly when the model attribute is updated'''

        if hasattr(self, "model"):
            self.values["model"] = self.model 

        elif self.values["model"] != None: # if a model is already present in the exposed values, use it
            self.model = self.values["model"]


        
    def _setup_values(self):
        super()._setup_values()
        


    def _setup_model(self):

        '''Sets up the model, loading it or initializing it'''

        self.lg.writeLine("Setting up model")
        
        model_loaded = self._is_model_loaded()

        if not model_loaded:

            self.lg.writeLine("Model is not loaded, trying to load it...")
            
            model_was_loaded = self._try_load_model()
            
            if model_was_loaded:
                self.lg.writeLine(f"Success in loading the model")

            else:
                self.lg.writeLine(f"Could not load model, initiating initialization strategy...")
                self._initialize_model() # initializes the model using passed values

            
        self.__synchro_model_value_attr()

        self._is_model_well_formed() # throws exception if model is not well formed

        self.lg.writeLine(f"Model setup is over")


    def _is_model_well_formed(self):
        '''Raises exception if model is not well formed'''
        if not self._is_model_loaded():
            raise Exception("Failed to load the model")
            
            
    def _is_model_loaded(self):
        return hasattr(self, "model") and self.model is not None
    

    def _try_load_model(self):
        '''Ties load model, and returns True if model was loaded, false otherwise'''

        model_was_loaded = self._try_load_model_from_input()

        if model_was_loaded:
            return model_was_loaded
        
        model_was_loaded = self._try_load_model_from_path()

        if model_was_loaded:
            return model_was_loaded

        return False
    
    
    def _try_load_model_from_input(self):

        '''Ties load model from input, and returns True if model was loaded, false otherwise'''

        self.lg.writeLine("Trying to load model from input....")

        input_model = self.get_input_value("model")

        if input_model != None:

            self.model : nn.Module = self.get_input_value("model")
            self.values["model"] = self.model
            self.lg.writeLine(f"Success in loading model from input")
            return True
        
        else:
            self.lg.writeLine("No model available in input to load")
            return False


    def _try_load_model_from_path(self):

        '''Ties load model from input, and returns True if model was loaded, false otherwise'''

        self.lg.writeLine("Trying to load model from path...")

        model_path = os.path.join(self.get_artifact_directory(), "model_weights.pth")
        
        if os.path.exists(model_path):
                
            state_dict = torch.load(model_path, map_location=torch.device('cpu'))
        
            self._initialize_mininum_model_architecture()  # Ensure the model as its architecture initialized before loading weights

            self.model.load_state_dict(state_dict) #loads the saved weights into the model

            self.lg.writeLine("Success in loading model from path")

            return True
        
        else:

            self.lg.writeLine("Could not find model weights to load (.../model_weights.pth)")
        
            return False


        
    def _initialize_mininum_model_architecture(self):

        '''Initializes the minimum architecture, this is used to load weights of the model, so the initial parameters are to be ignored'''

        self.lg.writeLine("Initializing minimum model architecture...")

        pass


    def _initialize_model(self):
        '''Initializes a totally new model'''
        
        self.lg.writeLine("Totally initializing model")
        
    # EXPOSED METHODS --------------------------------------------
    
    @requires_input_proccess
    def get_model_params(self):
        '''returns a list of model parameters'''
        return list(self.model.parameters())
    
    @requires_input_proccess
    def predict(self, state):
        super().predict(state)
        return self.model(state)

    
    @requires_input_proccess            
    def update_model_with_target(self, target_model, target_model_weight):
        
        '''
        Updates the weights of this model with the weights of the target model
        
        @param target_model_weight is the relevance of the target model, 1 will mean a total copy, 0 will do nothing, 0.5 will be an average between the models
        '''
        
        with torch.no_grad():
            this_model_state_dict = self.model.state_dict()
            target_model_state_dict = target_model.model.state_dict()

            for key in target_model_state_dict:
                this_model_state_dict[key] = (
                    target_model_state_dict[key] * target_model_weight + 
                    this_model_state_dict[key] * (1 - target_model_weight)
                )
            
            self.model.load_state_dict(this_model_state_dict)
    
    # UTIL -----------------------------------------------------
    
    @requires_input_proccess
    def clone(self):
        toReturn : TorchModelComponent = super().clone()
        toReturn.proccess_input_if_not_proccesd()
        toReturn.model.load_state_dict(self.model.state_dict())
        return toReturn
    
    # STATE MANAGEMENT -----------------------------------------------------

    def _save_state_internal(self):
        
        super()._save_state_internal()

        if hasattr(self, "model"):
            torch.save(self.model.state_dict(), os.path.join(self.get_artifact_directory(), "model_weights.pth"))
    
        else:
            globalWriteLine(f"{self.name}: WARNING: Saving state of Torch model state without ever reaching the point of initializing its model")
    
    
    def _load_state_internal(self) -> None:
        
        super()._load_state_internal()
                
        model_loaded_from_path = self._try_load_model_from_path()
        
        if model_loaded_from_path:

            globalWriteLine(f"{self.name}: Success in loading model from path when loading state")

        else:

            globalWriteLine(f"{self.name}: Failure in loading model from path when loading state")
